{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605bf9f2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4929df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a10a441",
   "metadata": {},
   "source": [
    "## Load Whisper Model\n",
    "\n",
    "Using the `base` model for a good balance between speed and accuracy. You can change to `tiny`, `small`, `medium`, or `large` based on your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f27b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FFmpeg found at: C:\\Users\\tomer\\AppData\\Local\\Microsoft\\WinGet\\Packages\\Gyan.FFmpeg.Essentials_Microsoft.Winget.Source_8wekyb3d8bbwe\\ffmpeg-8.0.1-essentials_build/bin\\ffmpeg.EXE\n",
      "   ffmpeg version 8.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# Check if ffmpeg is available\n",
    "ffmpeg_path = shutil.which(\"ffmpeg\")\n",
    "\n",
    "if ffmpeg_path:\n",
    "    print(f\"‚úÖ FFmpeg found at: {ffmpeg_path}\")\n",
    "    # Check version\n",
    "    try:\n",
    "        result = subprocess.run([\"ffmpeg\", \"-version\"], capture_output=True, text=True)\n",
    "        version_line = result.stdout.split('\\n')[0]\n",
    "        print(f\"   {version_line}\")\n",
    "    except:\n",
    "        print(\"   (Could not check version)\")\n",
    "else:\n",
    "    print(\"‚ùå FFmpeg NOT found!\")\n",
    "    print(\"\\n‚ö†Ô∏è  Please install ffmpeg:\")\n",
    "    print(\"   Option 1: winget install \\\"FFmpeg (Essentials Build)\\\"\")\n",
    "    print(\"   Option 2: Download from https://ffmpeg.org/download.html\")\n",
    "    print(\"   Option 3: Install via Chocolatey: choco install ffmpeg\")\n",
    "    print(\"\\n   After installation, restart this notebook kernel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1097dad5",
   "metadata": {},
   "source": [
    "## Check FFmpeg Installation\n",
    "\n",
    "Whisper requires ffmpeg to process audio files. Let's verify it's installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd49686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model...\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Whisper model...\")\n",
    "model = whisper.load_model(\"base\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f68c5e",
   "metadata": {},
   "source": [
    "## Transcribe Audio Files\n",
    "\n",
    "Process all audio files from `good_answers` and `bad_answers` folders, then save transcripts to separate output folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d770c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_folder(input_folder, output_folder, prefix):\n",
    "    \"\"\"\n",
    "    Transcribe all audio files in input_folder and save as text files in output_folder.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Path to folder containing audio files\n",
    "        output_folder: Path to save transcript text files\n",
    "        prefix: Prefix for output files (e.g., 'good' or 'bad')\n",
    "    \"\"\"\n",
    "    input_path = Path(input_folder)\n",
    "    output_path = Path(output_folder)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get all audio files (common audio extensions)\n",
    "    audio_extensions = {'.mp3', '.wav', '.m4a', '.flac', '.ogg', '.opus', '.webm'}\n",
    "    audio_files = sorted([f for f in input_path.iterdir() \n",
    "                         if f.is_file() and f.suffix.lower() in audio_extensions])\n",
    "    \n",
    "    if not audio_files:\n",
    "        print(f\"‚ö†Ô∏è  No audio files found in {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüìÅ Processing {len(audio_files)} files from {input_folder}...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, audio_file in enumerate(tqdm(audio_files, desc=f\"Transcribing {prefix}\")):\n",
    "        try:\n",
    "            # Transcribe audio\n",
    "            result = model.transcribe(str(audio_file), language=\"he\")  # Change language as needed\n",
    "            transcript = result[\"text\"]\n",
    "            \n",
    "            # Save transcript\n",
    "            output_file = output_path / f\"{prefix}_{idx+1:03d}.txt\"\n",
    "            output_file.write_text(transcript, encoding='utf-8')\n",
    "            \n",
    "            results.append({\n",
    "                'original_file': audio_file.name,\n",
    "                'transcript_file': output_file.name,\n",
    "                'text_length': len(transcript)\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {audio_file.name}: {e}\")\n",
    "            results.append({\n",
    "                'original_file': audio_file.name,\n",
    "                'transcript_file': 'ERROR',\n",
    "                'text_length': 0\n",
    "            })\n",
    "    \n",
    "    print(f\"‚úÖ Completed {prefix} transcriptions!\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac615487",
   "metadata": {},
   "source": [
    "### Process Good Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35219252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 33 files from ../data/good_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing good:   0%|          | 0/33 [00:00<?, ?it/s]c:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing good:   6%|‚ñå         | 2/33 [00:58<15:00, 29.05s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m good_df \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_folder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/good_answers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/good_answer_transcripts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgood\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display summary\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m good_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[4], line 32\u001b[0m, in \u001b[0;36mtranscribe_folder\u001b[1;34m(input_folder, output_folder, prefix)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, audio_file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(audio_files, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Transcribe audio\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Change language as needed\u001b[39;00m\n\u001b[0;32m     33\u001b[0m         transcript \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     35\u001b[0m         \u001b[38;5;66;03m# Save transcript\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:295\u001b[0m, in \u001b[0;36mtranscribe\u001b[1;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    293\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[1;32m--> 295\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:201\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[1;34m(segment)\u001b[0m\n\u001b[0;32m    198\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[1;32m--> 201\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    203\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    205\u001b[0m     compression_ratio_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m decode_result\u001b[38;5;241m.\u001b[39mcompression_ratio \u001b[38;5;241m>\u001b[39m compression_ratio_threshold\n\u001b[0;32m    207\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 120\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[1;34m(self, mel)\u001b[0m\n\u001b[0;32m    734\u001b[0m tokens \u001b[38;5;241m=\u001b[39m tokens\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(audio_features\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[1;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n\u001b[0;32m    740\u001b[0m audio_features \u001b[38;5;241m=\u001b[39m audio_features[:: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_group]\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\decoding.py:687\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[1;34m(self, audio_features, tokens)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample_len):\n\u001b[1;32m--> 687\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    689\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    690\u001b[0m             i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mno_speech \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    691\u001b[0m         ):  \u001b[38;5;66;03m# save no_speech_probs\u001b[39;00m\n\u001b[0;32m    692\u001b[0m             probs_at_sot \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msot_index]\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\decoding.py:163\u001b[0m, in \u001b[0;36mPyTorchInference.logits\u001b[1;34m(self, tokens, audio_features)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitial_token_length:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# only need to use the last token except in the first forward pass\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokens[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\model.py:242\u001b[0m, in \u001b[0;36mTextDecoder.forward\u001b[1;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[0;32m    239\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(xa\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 242\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln(x)\n\u001b[0;32m    245\u001b[0m logits \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    246\u001b[0m     x \u001b[38;5;241m@\u001b[39m torch\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_embedding\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdtype), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    247\u001b[0m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\model.py:167\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    162\u001b[0m     x: Tensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m     kv_cache: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    166\u001b[0m ):\n\u001b[1;32m--> 167\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_ln\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkv_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkv_cache\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn:\n\u001b[0;32m    169\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn_ln(x), xa, kv_cache\u001b[38;5;241m=\u001b[39mkv_cache)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\model.py:104\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[0;32m     99\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery(x)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kv_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kv_cache:\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;66;03m# hooks, if installed (i.e. kv_cache is not None), will prepend the cached kv tensors;\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# otherwise, perform key/value projections for self- or cross-attention as usual.\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    105\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue(x \u001b[38;5;28;01mif\u001b[39;00m xa \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m xa)\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;66;03m# for cross-attention, calculate keys and values once and reuse in subsequent calls.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1879\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m   1878\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1881\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[0;32m   1882\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[0;32m   1883\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[0;32m   1884\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1840\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1838\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[0;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1840\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1843\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[1;32mc:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\model.py:332\u001b[0m, in \u001b[0;36mWhisper.install_kv_cache_hooks.<locals>.save_to_cache\u001b[1;34m(module, _, output)\u001b[0m\n\u001b[0;32m    330\u001b[0m     cache[module] \u001b[38;5;241m=\u001b[39m output\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 332\u001b[0m     cache[module] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[module]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "good_df = transcribe_folder(\n",
    "    input_folder=\"../data/good_answers\",\n",
    "    output_folder=\"../data/good_answer_transcripts\",\n",
    "    prefix=\"good\"\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "if good_df is not None:\n",
    "    display(good_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701de650",
   "metadata": {},
   "source": [
    "### Process Bad Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7247e20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_001.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_002.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_001.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_002.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing bad:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_001.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_002.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing bad:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_003.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_004.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_005.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_006.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_007.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_008.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_009.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_010.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_001.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_002.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing bad:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_003.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_004.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_005.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_006.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_007.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_008.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_009.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_010.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 49.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Processing 13 files from ../data/bad_answers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad:   0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_001.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_002.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tomer\\OneDrive\\◊û◊°◊û◊õ◊ô◊ù\\GitHub\\customer-support-llm\\.venv\\lib\\site-packages\\whisper\\transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "Transcribing bad:  23%|‚ñà‚ñà‚ñé       | 3/13 [00:00<00:00, 29.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_003.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_004.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_005.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_006.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_007.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_008.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_009.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_010.m4a: [WinError 2] The system cannot find the file specified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing bad: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [00:00<00:00, 49.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Error processing bad_011.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_012.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚ùå Error processing bad_013.m4a: [WinError 2] The system cannot find the file specified\n",
      "‚úÖ Completed bad transcriptions!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_file</th>\n",
       "      <th>transcript_file</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bad_001.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bad_002.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bad_003.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad_004.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bad_005.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bad_006.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bad_007.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bad_008.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bad_009.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bad_010.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bad_011.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bad_012.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bad_013.m4a</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_file transcript_file  text_length\n",
       "0    bad_001.m4a           ERROR            0\n",
       "1    bad_002.m4a           ERROR            0\n",
       "2    bad_003.m4a           ERROR            0\n",
       "3    bad_004.m4a           ERROR            0\n",
       "4    bad_005.m4a           ERROR            0\n",
       "5    bad_006.m4a           ERROR            0\n",
       "6    bad_007.m4a           ERROR            0\n",
       "7    bad_008.m4a           ERROR            0\n",
       "8    bad_009.m4a           ERROR            0\n",
       "9    bad_010.m4a           ERROR            0\n",
       "10   bad_011.m4a           ERROR            0\n",
       "11   bad_012.m4a           ERROR            0\n",
       "12   bad_013.m4a           ERROR            0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bad_df = transcribe_folder(\n",
    "    input_folder=\"../data/bad_answers\",\n",
    "    output_folder=\"../data/bad_answer_transcripts\",\n",
    "    prefix=\"bad\"\n",
    ")\n",
    "\n",
    "# Display summary\n",
    "if bad_df is not None:\n",
    "    display(bad_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c12ba",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TRANSCRIPTION SUMMARY\n",
      "==================================================\n",
      "\n",
      "‚úÖ Good Answers:\n",
      "   Files processed: 33\n",
      "   Avg text length: 0 chars\n",
      "   Total text: 0 chars\n",
      "\n",
      "‚ùå Bad Answers:\n",
      "   Files processed: 13\n",
      "   Avg text length: 0 chars\n",
      "   Total text: 0 chars\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\"TRANSCRIPTION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if good_df is not None:\n",
    "    print(f\"\\n‚úÖ Good Answers:\")\n",
    "    print(f\"   Files processed: {len(good_df)}\")\n",
    "    print(f\"   Avg text length: {good_df['text_length'].mean():.0f} chars\")\n",
    "    print(f\"   Total text: {good_df['text_length'].sum():,} chars\")\n",
    "\n",
    "if bad_df is not None:\n",
    "    print(f\"\\n‚ùå Bad Answers:\")\n",
    "    print(f\"   Files processed: {len(bad_df)}\")\n",
    "    print(f\"   Avg text length: {bad_df['text_length'].mean():.0f} chars\")\n",
    "    print(f\"   Total text: {bad_df['text_length'].sum():,} chars\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
