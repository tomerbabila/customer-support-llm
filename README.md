# customer-support-llm

Fine-tune language models for customer support using Whisper transcription and Hebrew AlephBERT.

This project:

1. **Transcribes** audio recordings (good and bad customer support answers) using OpenAI's Whisper
2. **Prepares** transcripts as training data
3. **Fine-tunes** a Hebrew BERT model to classify answer quality

## Quick Links

- **New to this project?** Start with [Quick Start Guide](docs/QUICKSTART.md)
- **Adding training data?** See [Data Setup Guide](docs/DATA_SETUP.md)
- **Understanding dependencies?** Check [Dependencies Guide](docs/DEPENDENCIES.md)
- **Testing your model?** Read [Testing Guide](docs/TESTING.md)
- **Deploying to Hugging Face?** See [Deployment Guide](docs/DEPLOYMENT.md)
- **Having issues?** Read [Troubleshooting Guide](docs/TROUBLESHOOTING.md)

## Workflow

```
1. data_processing.ipynb
   ├─ Load Whisper (base model)
   ├─ Transcribe audio files
   └─ Save transcripts as .txt

2. model_finetuning.ipynb
   ├─ Load transcripts
   ├─ Split train/validation
   ├─ Fine-tune AlephBERT (Hebrew BERT)
   └─ Save classifier model
```

## What's Inside

```
notebooks/
  ├── data_processing.ipynb      # Step 1: Whisper transcription
  └── model_finetuning.ipynb     # Step 2: Fine-tune classifier

scripts/
  └── normalize_data_names.py    # Rename audio files consistently

data/ (git-ignored)
  ├── good_answers/              # Your audio files (good answers)
  ├── good_answer_transcripts/   # Generated by Whisper
  ├── bad_answers/               # Your audio files (bad answers)
  └── bad_answer_transcripts/    # Generated by Whisper

models/ (git-ignored)
  └── customer-support-classifier-final/  # Fine-tuned model
```

## Key Features

✅ **Automatic transcription** - Whisper speech-to-text in Hebrew  
✅ **Consistent naming** - Script ensures team uses same file format  
✅ **Interactive workflows** - Jupyter notebooks for exploration  
✅ **Hebrew NLP** - AlephBERT fine-tuning for Hebrew text  
✅ **Reproducible setup** - Virtual environment with pinned dependencies

## Prerequisites

- **Python 3.11** (3.10+ minimum)
- **ffmpeg** (for audio processing)
- **Git**
- 4GB+ disk space for models

## Get Started

See [Quick Start Guide](docs/QUICKSTART.md) for step-by-step setup.

## Workflow Overview

### Step 1: Transcription (data_processing.ipynb)

- Add your audio files to `data/good_answers/` and `data/bad_answers/`
- Run the transcription notebook
- Whisper generates text files in `good_answer_transcripts/` and `bad_answer_transcripts/`

### Step 2: Fine-tuning (model_finetuning.ipynb)

- Loads all transcripts
- Splits into train/validation (80/20)
- Fine-tunes AlephBERT for 3 epochs
- Saves model to `models/customer-support-classifier-final/`

## Collaboration

This setup is designed for team collaboration:

1. **Virtual environment** - Each person has their own `.venv` (not committed to Git)
2. **Consistent naming** - Run `python scripts/normalize_data_names.py` for standardized filenames
3. **Data storage** - `data/` and `models/` folders are git-ignored; manage locally or use shared storage
4. **Code sharing** - All notebooks and scripts are version-controlled

## License & Credits

- **Whisper** by OpenAI - [GitHub](https://github.com/openai/whisper)
- **AlephBERT** by OnlpLab - [Hugging Face](https://huggingface.co/onlplab/alephbert-base)
- **Transformers** by Hugging Face - [huggingface.co](https://huggingface.co)
